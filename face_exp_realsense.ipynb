{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    \n",
    "    if len(List) != 0:\n",
    "        counter = 0\n",
    "        value = List[0]\n",
    "     \n",
    "        for i in List:\n",
    "            curr_frequency = List.count(i)\n",
    "            if(curr_frequency> counter):\n",
    "                counter = curr_frequency\n",
    "                value = i\n",
    "    \n",
    "        return value\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def make_bounding_box(filtered_faces,filtered_labels,max_appeared_label,frame):\n",
    "    for per_person in range(max_appeared_label):\n",
    "            per_person_face = filtered_faces[:,per_person]\n",
    "            per_person_emotion = filtered_labels[:,per_person]\n",
    "        \n",
    "            final_label = most_frequent([i for i in per_person_emotion])\n",
    "            x,y,w,h = per_person_face[np.where(per_person_emotion == final_label)][0]\n",
    "            \n",
    "            label_position = (x,y)\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,145,255),1)\n",
    "            cv2.putText(frame,final_label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class DepthCamera:\n",
    "    def __init__(self):\n",
    "        # Configure depth and color streams\n",
    "        self.pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "\n",
    "        # Get device product line for setting a supporting resolution\n",
    "        pipeline_wrapper = rs.pipeline_wrapper(self.pipeline)\n",
    "        pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "        device = pipeline_profile.get_device()\n",
    "        device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "\n",
    "\n",
    "        # Start streaming\n",
    "        self.pipeline.start(config)\n",
    "\n",
    "    def get_frame(self):\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        if not depth_frame or not color_frame:\n",
    "            return False, None, None\n",
    "        return True, depth_image, color_image\n",
    "\n",
    "    def release(self):\n",
    "        self.pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fer() missing 1 required positional argument: 'frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Balaji_j\\atum_prj\\Face_emotion_recognition\\face_exp_realsense.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Balaji_j/atum_prj/Face_emotion_recognition/face_exp_realsense.ipynb#ch0000003?line=27'>28</a>\u001b[0m val,depth_frame,color_frame \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mget_frame()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Balaji_j/atum_prj/Face_emotion_recognition/face_exp_realsense.ipynb#ch0000003?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m val :\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Balaji_j/atum_prj/Face_emotion_recognition/face_exp_realsense.ipynb#ch0000003?line=29'>30</a>\u001b[0m     labels,faces \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mModel\u001b[39m.\u001b[39;49mfer(color_frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Balaji_j/atum_prj/Face_emotion_recognition/face_exp_realsense.ipynb#ch0000003?line=31'>32</a>\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39m!=\u001b[39m []:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Balaji_j/atum_prj/Face_emotion_recognition/face_exp_realsense.ipynb#ch0000003?line=32'>33</a>\u001b[0m         tot_labels_set\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray(labels))\n",
      "\u001b[1;31mTypeError\u001b[0m: fer() missing 1 required positional argument: 'frame'"
     ]
    }
   ],
   "source": [
    "# Initialize Camera Intel Realsense\n",
    "dc = DepthCamera()\n",
    "cv2.namedWindow(\"Color frame\")\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     ret, depth_frame, color_frame = dc.get_frame()\n",
    "    \n",
    "\n",
    "#     cv2.imshow(\"depth frame\", depth_frame)\n",
    "#     cv2.imshow(\"Color frame\", color_frame)\n",
    "#     key = cv2.waitKey(1)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "            tot_labels_set = []\n",
    "            tot_faces_set = []\n",
    "\n",
    "            frame = None\n",
    "\n",
    "            val = True\n",
    "            \n",
    "            for frm_of_set in range(30):\n",
    "                val,depth_frame,color_frame = dc.get_frame()\n",
    "                if val :\n",
    "                    labels,faces = model.Model.fer(color_frame)\n",
    "\n",
    "                    if labels != []:\n",
    "                        tot_labels_set.append(np.array(labels))\n",
    "                        tot_faces_set.append(np.array(faces))\n",
    "            \n",
    "\n",
    "            if val :\n",
    "                    tot_faces_set = np.array(tot_faces_set)\n",
    "                    tot_labels_set = np.array(tot_labels_set)\n",
    "\n",
    "                    max_appeared_label = most_frequent([len(i) for i in tot_labels_set ])\n",
    "\n",
    "                    #filtered according to the max no appeared faces found in each frame to filter \n",
    "                    filtered_indexes = [index for index in range(len(tot_labels_set)) if len(tot_labels_set[index])==max_appeared_label]\n",
    "\n",
    "                    filtered_labels= np.array([tot_labels_set[index] for index in filtered_indexes ])\n",
    "                    filtered_faces = np.array([tot_faces_set[index] for index in filtered_indexes ])\n",
    "\n",
    "                    if max_appeared_label >= 1:  \n",
    "                    \n",
    "                        make_bounding_box(filtered_faces,filtered_labels,max_appeared_label,frame)\n",
    "\n",
    "                        cv2.imshow('Emotion Detector',frame)\n",
    "                        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                            break\n",
    "                        else:\n",
    "                            count = count+1\n",
    "                            continue\n",
    "                        \n",
    "                    else:\n",
    "\n",
    "                        cv2.putText(frame,'No Faces',(179,59),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "                        cv2.imshow('Emotion Detector',frame)\n",
    "                        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                            break\n",
    "                        else: \n",
    "                            count = count+1\n",
    "                            continue\n",
    "            else:\n",
    "                break        \n",
    "                        \n",
    "                        \n",
    "    \n",
    "print(count)\n",
    "cv2.destroyAllWindows()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f86bd2566df633de3433ebe1e2d10776a9b4d657b73edceb2d78e2ba4453e4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
