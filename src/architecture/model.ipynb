{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/yaoing/DAN\n",
    "# #imports\n",
    "import os\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#DAN ARCHIETURE \n",
    "\n",
    "class DAN(nn.Module):\n",
    "    def __init__(self, num_class=7,num_head=4, pretrained=True):\n",
    "        super(DAN, self).__init__()\n",
    "        \n",
    "        resnet = models.resnet18(pretrained)\n",
    "        \n",
    "        if pretrained:\n",
    "            checkpoint = torch.load('./models/resnet18_msceleb.pth')\n",
    "            resnet.load_state_dict(checkpoint['state_dict'],strict=True)\n",
    "\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.num_head = num_head\n",
    "        for i in range(num_head):\n",
    "            setattr(self,\"cat_head%d\" %i, CrossAttentionHead())\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc = nn.Linear(512, num_class)\n",
    "        self.bn = nn.BatchNorm1d(num_class)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        heads = []\n",
    "        for i in range(self.num_head):\n",
    "            heads.append(getattr(self,\"cat_head%d\" %i)(x))\n",
    "        \n",
    "        heads = torch.stack(heads).permute([1,0,2])\n",
    "        if heads.size(1)>1:\n",
    "            heads = F.log_softmax(heads,dim=1)\n",
    "            \n",
    "        out = self.fc(heads.sum(dim=1))\n",
    "        out = self.bn(out)\n",
    "   \n",
    "        return out, x, heads\n",
    "\n",
    "class CrossAttentionHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sa = SpatialAttention()\n",
    "        self.ca = ChannelAttention()\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "    def forward(self, x):\n",
    "        sa = self.sa(x)\n",
    "        ca = self.ca(sa)\n",
    "\n",
    "        return ca\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1x1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        self.conv_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "        self.conv_1x3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=(1,3),padding=(0,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "        self.conv_3x1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=(3,1),padding=(1,0)),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1x1(x)\n",
    "        y = self.relu(self.conv_3x3(y) + self.conv_1x3(y) + self.conv_3x1(y))\n",
    "        y = y.sum(dim=1,keepdim=True) \n",
    "        out = x*y\n",
    "        \n",
    "        return out \n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(512, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 512),\n",
    "            nn.Sigmoid()    \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, sa):\n",
    "        sa = self.gap(sa)\n",
    "        sa = sa.view(sa.size(0),-1)\n",
    "        y = self.attention(sa)\n",
    "        out = sa * y\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.data_transforms = transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "        self.labels = ['neutral', 'happy', 'sad', 'surprise', 'fear', 'disgust', 'anger']\n",
    "\n",
    "        self.model = DAN(num_head=4, num_class=7, pretrained=False)\n",
    "        checkpoint = torch.load(r\"affecnet7_epoch6_acc0.6569.pth\",\n",
    "            map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    def detect(self, img0):\n",
    "        img = cv2.cvtColor(np.asarray(img0),cv2.COLOR_RGB2BGR)\n",
    "        faces = self.face_cascade.detectMultiScale(img,minNeighbors = 10,minSize=(60,60))\n",
    "    \n",
    "        return faces\n",
    "\n",
    "    def fer(self, frame):\n",
    "\n",
    "        img0 = Image.fromarray(frame)\n",
    "\n",
    "        faces = self.detect(img0)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            return [],[]\n",
    "\n",
    "        #  single face detection\n",
    "        labels = []\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "             img = img0.crop((x,y, x+w, y+h))\n",
    "\n",
    "             img = self.data_transforms(img)\n",
    "             img = img.view(1,3,224,224)\n",
    "             img = img.to(self.device)\n",
    "            \n",
    "             with torch.set_grad_enabled(False):\n",
    "                 out, _, _ = self.model(img)\n",
    "                 _, pred = torch.max(out,1)\n",
    "                 index = int(pred)\n",
    "                 label = self.labels[index]\n",
    "                 labels.append(label)\n",
    "        return labels,faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.data_transforms = transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "        self.labels = ['neutral', 'happy', 'sad', 'surprise', 'fear', 'disgust', 'anger']\n",
    "\n",
    "        self.model = DAN(num_head=4, num_class=7, pretrained=False)\n",
    "        checkpoint = torch.load(r\"affecnet7_epoch6_acc0.6569.pth\",\n",
    "            map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'],strict=True)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    def detect(self, img0):\n",
    "        img = cv2.cvtColor(np.asarray(img0),cv2.COLOR_RGB2BGR)\n",
    "        faces = self.face_cascade.detectMultiScale(img,minNeighbors = 10,minSize=(60,60))\n",
    "    \n",
    "        return faces\n",
    "\n",
    "    def fer(self, frame):\n",
    "\n",
    "        img0 = Image.fromarray(frame)\n",
    "\n",
    "        faces = self.detect(img0)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            return [],[]\n",
    "\n",
    "        #  single face detection\n",
    "        labels = []\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "             img = img0.crop((x,y, x+w, y+h))\n",
    "\n",
    "             img = self.data_transforms(img)\n",
    "             img = img.view(1,3,224,224)\n",
    "             img = img.to(self.device)\n",
    "            \n",
    "             with torch.set_grad_enabled(False):\n",
    "                 out, _, _ = self.model(img)\n",
    "                 _, pred = torch.max(out,1)\n",
    "                 index = int(pred)\n",
    "                 label = self.labels[index]\n",
    "                 labels.append(label)\n",
    "        return labels,faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f86bd2566df633de3433ebe1e2d10776a9b4d657b73edceb2d78e2ba4453e4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
